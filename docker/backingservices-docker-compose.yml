version: '3.8'
networks:
  restorecommerce:
volumes:
  kafka_data:
  redis_data:
  arangodb_data:
  aragodb_apps_data:
  cloudserver_data:
  elasticsearch_data:
services:
  kafka:
    container_name: kafka
    image: bitnami/kafka:3.3.1
    hostname: kafka
    ports:
      - "9092:9092"
    deploy:
      resources:
        limits:
          memory: 6144m
    networks:
      - restorecommerce
    environment:
      KAFKA_ENABLE_KRAFT: 'yes'
      KAFKA_CFG_PROCESS_ROLES: broker,controller
      KAFKA_CFG_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_BROKER_ID: 1
      KAFKA_CFG_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_CFG_ADVERTISED_LISTENERS: PLAINTEXT://127.0.0.1:9092
      KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      ALLOW_PLAINTEXT_LISTENER: 'yes'
      KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_CFG_DELETE_TOPIC_ENABLE: 'true'
      KAFKA_CFG_LOG_RETENTION_HOURS: -1
      KAFKA_CFG_CONTROLLER_QUORUM_VOTERS: 1@127.0.0.1:9093
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - kafka_data:/bitnami/kafka
    healthcheck:
      test: ["CMD", "bash", "-c", "unset" , "JMX_PORT" ,";" ,"/opt/bitnami/kafka/bin/kafka-topics.sh","--zookeeper","zookeeper:2181","--list"]
  redis:
    container_name: redis
    hostname: redis
    image: redis:7.0.5-alpine
    ports:
      - "6379:6379"
    deploy:
      resources:
        limits:
          memory: 1024m
    volumes:
      - redis_data:/data
    networks:
      - restorecommerce
    healthcheck:
      test: "redis-cli ping"
  arangodb:
    container_name: arangodb
    image: arangodb/arangodb:3.10.0
    hostname: arangodb
    ports:
      - "8529:8529"
    deploy:
      resources:
        limits:
          memory: 2048m
    volumes:
      - arangodb_data:/var/lib/arangodb3
      - aragodb_apps_data:/var/lib/arangodb3-apps
    networks:
      - restorecommerce
    environment:
      ARANGO_NO_AUTH: 1
    healthcheck:
      test: "wget -O - localhost:8529/_api/version"
    # command: arangod --database.auto-upgrade=true
  cloudserver:
    container_name: cloudserver
    hostname: cloudserver
    image: zenko/cloudserver:latest-7.70.10
    ports:
      - "8000:8000"
      - "9990:9990"
      - "9991:9991"
    networks:
      - restorecommerce
    environment:
      CLOUDSERVER_ACCESS_KEY: accessKey1
      CLOUDSERVER_SECRET_KEY: verySecretKey1
    volumes:
      - cloudserver_data:/data
  elasticsearch:
    container_name: restorecommerce_elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:8.4.3
    hostname: elasticsearch
    ports:
      - "9200:9200"
      - "9300:9300"
    deploy:
      resources:
        limits:
          memory: 6144m
    networks:
      - restorecommerce
    environment:
      - xpack.security.enabled=false
      - xpack.security.transport.ssl.enabled=false
      - xpack.security.http.ssl.enabled=false
      - cluster.name=cluster
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms3g -Xmx3g"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: "if [[ $$(curl -fsSL 'http://localhost:9200/_cat/health?h=status' | sed -r 's/^[[:space:]]+|[[:space:]]+$$//g') != 'red' ]]; then exit 0; else exit 1; fi"
  kibana:
    container_name: restorecommerce_kibana
    image: docker.elastic.co/kibana/kibana:8.4.3
    hostname: kibana
    environment:
      SERVER_NAME: localhost
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    ports:
      - "5601:5601"
    deploy:
      resources:
        limits:
          memory: 1024m
    networks:
      - restorecommerce
    depends_on:
      - elasticsearch
    healthcheck:
      test: "exit 0"
